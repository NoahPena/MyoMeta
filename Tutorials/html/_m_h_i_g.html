<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.8"/>
<title>Meta Human Interface Guidelines</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="customdoxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="MetaSDKDocsLogo.fw.png"/></td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.8 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Home</span></a></li>
      <li class="current"><a href="pages.html"><span>Guides</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('_m_h_i_g.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Properties</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title"><a class="el" href="namespace_meta.html" title="The Meta namespace contains the Meta SDK&#39;s classes. ">Meta</a> Human Interface Guidelines </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="MHIGIntro"></a>
Meta Human Interface Guidelines</h1>
<div class="image">
<img src="HologramsAndPanels.jpg" alt="HologramsAndPanels.jpg"/>
<div class="caption">
Holograms are manipulatable 3D objects and panels are flat touch screens.</div></div>
<p> This is a guide to designing Meta human interfaces from a user experience perspective. To learn about coding Meta Apps, see the <a class="el" href="_m_a_p_g.html">Meta App Programming Guide</a>.</p>
<ul>
<li>If you are familiar with making user interfaces for web, mobile, desktop and game applications, you will find much that is familiar to you.</li>
<li>If you have experience as a designer of 2D user interfaces with image editing and/or motion graphics tools, like Adobe Fireworks, Photoshop, and Flash, you can learn how to mock up interfaces and import graphic and video assets from the programs you use to do concept work. Learn more in the <a class="el" href="_m_h_i_g.html#GraphicsImport">Graphics Import Guide</a>.</li>
</ul>
<h1><a class="anchor" id="MetaSpace"></a>
The MetaSpace OS</h1>
<p>The MetaSpace operating system enhances the world around us by adding interactivity. Meta's philosophy is to make Meta augmented reality as intuitive as possible for both new and continuing users.</p>
<h2>Principles</h2>
<ul>
<li><b>Naturalness:</b> Things should do what you would expect them to do if you touched them in the real world. Gestures such as grab, swipe or touch are based on true reality for the most natural approach.</li>
<li><b>Familiarity:</b> Implementing user interface concepts people already know makes it easier to learn holographic interfaces. We are using familiarity so that users are be able to bring what they know into the AR world with the easiest approach.</li>
<li><b>Discoverability</b>: Interfaces should suggest their interactivity so that you have some idea what they are able to do before you try it.</li>
<li><b>Metaphysicality:</b> Objects should feel physically responsive to our kinetic touch and our telekinetic gestures. They should behave predictably according to our intentions as though the system understands what it is that the users are trying to achieve.</li>
</ul>
<h2>True Augmented Reality</h2>
<ul>
<li><b>Additive graphics:</b> The graphics can brighten reality but not darken it, so black is see-through and white-on-black becomes white-over-reality.</li>
<li><b>See-through glasses:</b> You can see reality normally, with Meta graphics projected in front of your eyes so virtual objects appear to be part of the real world.</li>
<li><b>Natural gestural interface:</b> You can use gestures as you would in reality to navigate through the Meta augmented reality.</li>
</ul>
<h1><a class="anchor" id="MetaUI"></a>
Meta User Interface</h1>
<h2><a class="anchor" id="PanelsAndHolograms"></a>
Panels &amp; Holograms</h2>
<p>Meta has 2 main kinds of interfaces: panels and holograms.</p>
<ul>
<li><b>Panels:</b> 2D GUIs projected onto planes in 3D with gestures emulating a mouse.</li>
<li><b>Holograms:</b> 3D objects you touch with your hands to manipulate.</li>
</ul>
<h2><a class="anchor" id="LearningMeta"></a>
Learning a holographic interface</h2>
<p>Meta 3D user interfaces have many new capabilities. When users first use Meta, they are introduced to the natural user interface, one interaction at a time. The flow introduces users to using Meta, and it introduces designers to the interaction techniques that will be explained in this guide.</p>
<table class="doxtable">
<tr>
<th>Instruction </th><th>What happens  </th></tr>
<tr>
<td>Put up your hands </td><td>First a user puts up their hands and sees that the depth sensor can track them </td></tr>
<tr>
<td>Navigate menus </td><td>Begin navigating the Meta SDK Guide to learn more about the rest of the system </td></tr>
<tr>
<td>Grab the cube </td><td>You can grab a holographic cube in your hand and move it around. </td></tr>
</table>
<h1><a class="anchor" id="HumanCalibration"></a>
Human Calibration</h1>
<h2><a class="anchor" id="Reach"></a>
User Reach Distance</h2>
<ul>
<li>The orbital space can scale automatically to the user's height. When a user first uses Meta and creates their profile, there is an option to input the user's reach distance. For more information, see <a class="el" href="_basics.html#UserSettings">User Settings</a>.</li>
</ul>
<div class="image">
<img src="ReachDistance.jpg" alt="ReachDistance.jpg"/>
<div class="caption">
Reach distance</div></div>
<h2><a class="anchor" id="IPD"></a>
IPD</h2>
<p>Interpupillary distance (IPD) is the distance between the center of the pupils of the two eyes. IPD is critical for the design of binocular viewing systems, where both eye pupils need to be positioned within the exit pupils of the viewing system. These viewing systems include binocular microscopes, night vision devices or goggles (NVGs), and head-mounted displays (HMDs) like Meta.</p>
<p>To measure your IPD, put a ruler in front of your face and use your fingers to match where your pupils are located.</p>
<p>Alternatively, you can try the <a href="http://pd.warbyparker.com/">Warby Parker Webcam IPD Measurement Tool</a> if you have a webcam. This will take a photo of you while holding a credit card or business card (they are 3.5" or 88.9mm across) in order to calculate your IPD.</p>
<p>This measurement is not needed by Meta, as we perform our own calibration method. Understanding IPDs, however, will assist in your understanding of human perception of objects in augmented 3D space.</p>
<div class="image">
<img src="IPDCalibration.jpg" alt="IPDCalibration.jpg"/>
<div class="caption">
IPD calibration is important</div></div>
<p> Human IPD values (mm) from <a href="http://en.wikipedia.org/wiki/Interpupillary_distance">1988 Army Survey</a></p>
<table class="doxtable">
<tr>
<th>Gender </th><th>Sample size </th><th>Mean </th><th>Standard deviation </th><th>Minimum </th><th>Maximum </th><th>1% Percentile </th><th>5% </th><th>50% </th><th>95% </th><th>99%  </th></tr>
<tr>
<td>Male </td><td>1771 </td><td>64.7 </td><td>3.7 </td><td>52 </td><td>78 </td><td>57 </td><td>59 </td><td>65 </td><td>71 </td><td>74 </td></tr>
<tr>
<td>Female </td><td>2205 </td><td>62.3 </td><td>3.6 </td><td>52 </td><td>76 </td><td>55 </td><td>57 </td><td>62 </td><td>69 </td><td>71 </td></tr>
</table>
<h3><a class="el" href="namespace_meta.html" title="The Meta namespace contains the Meta SDK&#39;s classes. ">Meta</a> 1 Development Kit FOV expander Lens</h3>
<p>Meta 1 Development Kit provides an FOV expander Lens, adjustable physically to your personal IPD. For more information please refer to <a class="el" href="_setup_guide.html#Meta1DK">Meta 1 Development Kit Features</a>.</p>
<h1><a class="anchor" id="InterfaceFundamentals"></a>
Meta UI Fundamentals</h1>
<h2><a class="anchor" id="Touch"></a>
Touch Input and Stereo Display</h2>
<p>The defining features of a human interface are its input and output.</p>
<p>We are used to putting our hands on mouse, keyboard, and touch inputs and looking with our eyes at flat panel display outputs. Interaction with your hands are your primary input method in Meta and your body and head tracking to navigate through Meta augmented reality. Your eyes see stereoscopic graphics on see-through projector screens by overlaying light on top of reality.</p>
<h3><a class="anchor" id="DisplayOutput"></a>
Display Output</h3>
<p>Meta glasses provide stereoscopic graphics.</p>
<table class="doxtable">
<tr>
<th>Display Mode </th><th>Keyboard Shortcut </th><th>Purpose  </th></tr>
<tr>
<td>Mono </td><td>F2 </td><td>Single-camera mode for use with RGB feed for observers and videos </td></tr>
<tr>
<td>Stereo </td><td>F2 </td><td>Splits the screen between 2 eyes for a 3D view </td></tr>
<tr>
<td>Rectified Stereo </td><td>F3 </td><td>1:1 true-scale use of Meta 1 UI &amp; zoomed use of future Meta UI </td></tr>
<tr>
<td>Wide-angle Stereo </td><td>F3 </td><td>Multi-tasking, High <a class="el" href="_m_h_i_g.html#FOV">Field of View</a> Meta UI prototyping </td></tr>
<tr>
<td>Demo Mode Mono with RGB </td><td>F7 </td><td>Showing Meta use to observers, recording screencasts </td></tr>
</table>
<h3><a class="anchor" id="FOV"></a>
Field of View</h3>
<table class="doxtable">
<tr>
<th>Device </th><th>FOV </th><th>Width </th><th>Purpose  </th></tr>
<tr>
<td>Meta 1 UI </td><td>23 deg </td><td>15cm </td><td>The Meta 1 Dev Kit glasses have a 23 degree field of view with a 960 x 540 resolution (480x540 per eye). When plugged into the computer, you will typically run them at a 1280 x 720 resolution. </td></tr>
<tr>
<td>Next-gen Meta UI </td><td>40+ deg </td><td>50+cm </td><td>Future Meta devices will expand the field of view and enable larger interfaces. </td></tr>
</table>
<p>The field of view determines how much of the visible area you can see.</p>
<p>Take this into consideration when designing UX for Meta:</p>
<ul>
<li>Keep your interfaces under 15cm wide (the default width of MGUIPanels).</li>
<li>Keep holographic objects within the middle of your panels for optimal stereoscopic visibility to both eyes at once.</li>
</ul>
<div class="image">
<img src="MetaHumanCalibrationDiagram.jpg" alt="MetaHumanCalibrationDiagram.jpg"/>
<div class="caption">
A diagram of the areas that are comfortably reachable and stereoscopically visible to both eyes</div></div>
 <h2><a class="anchor" id="Input"></a>
Input Methods</h2>
<p>Meta provides multiple sources of input.</p>
<table class="doxtable">
<tr>
<th>Input Source </th><th>Purpose  </th></tr>
<tr>
<td>Gestures (direct) </td><td>Touch and manipulate objects </td></tr>
<tr>
<td>Gestures (indirect) </td><td>Aim gestures at something focused on from afar </td></tr>
<tr>
<td>Meta keyboard </td><td>The Meta hologram keyboard appears when you focus on text controls </td></tr>
<tr>
<td>Gaze Focus </td><td>Looking at objects to focus for interaction </td></tr>
<tr>
<td>Gaze Angle </td><td>Looking up or down to activate sky and belt-level Apps </td></tr>
<tr>
<td>Mouse </td><td>Gestures via mouse click, head tracking via right mouse drag </td></tr>
<tr>
<td>Physical keyboard </td><td>Input typing, emulates holodeck moving via WASD keys, UIInput </td></tr>
</table>
<h3><a class="anchor" id="MetaKeyboard"></a>
Meta Keyboard</h3>
<p>The Meta keyboard allows you to tap any text input field and type on virtual floating keys in the absence of a physical input device such as a Bluetooth pocket keyboard.</p>
<div class="image">
<img src="MetaKeyboard.jpg" alt="MetaKeyboard.jpg"/>
<div class="caption">
The Meta Keyboard appears when you touch MGUIInput fields.</div></div>
<h3><a class="anchor" id="HeadTracking"></a>
Head Tracking Gaze</h3>
<p>Gaze can be at a single point in front of your eye over the focal point or project outwards onto the target in a way that gives you feedback that you can do something with it.</p>
<ul>
<li><b>Focus:</b> The object you look at can show visual selection feedback and respond to aimed gestures.</li>
<li><b>Angular sky-level interactions:</b> Things which only appear when looking up at the sky or down at the ground.</li>
<li><b>Gaze-aimed gestures:</b> Use gaze like a mouse, and peripheral gestures like clicks and keyboard commands.</li>
</ul>
<h3><a class="anchor" id="Mouse"></a>
Mouse</h3>
<p>If you do not have your Meta glasses plugged in, you will be able to look around your application with the mouse.</p>
<table class="doxtable">
<tr>
<th>Mouse Action </th><th>Emulated Gesture  </th></tr>
<tr>
<td>Hold right-click down and move around </td><td>Looking around the scene </td></tr>
<tr>
<td>Left-click down on GUI elements </td><td>Pointer finger tapping down on a GUI element </td></tr>
</table>
<p>Known issues with mouse look:</p><ul>
<li>You can only use mouselook in monocular mode (press F2)</li>
<li>You cannot yet touch, grab, or pinch non-GUI elements</li>
<li>Clicking keyboard keys also clicks GUI elements behind them</li>
</ul>
<h3><a class="anchor" id="Keyboard"></a>
Physical Keyboard</h3>
<p>You can use a pocket-sized Bluetooth keyboard for long-form text entry.</p>
<p>You can also use it for movement emulation to move around a holodeck scene with the WASD keys.</p>
<h2><a class="anchor" id="Gestures"></a>
Gestures</h2>
<p>Gestures are at the heart of interacting with Meta Apps. Naturalness and consistency of gesture interactions across Apps is important.</p>
<h3><a class="anchor" id="TouchGestures"></a>
Touch gestures</h3>
<p>Touch manipulation gestures are actions that let you directly interact with objects in space.</p>
<table class="doxtable">
<tr>
<th align="left">Touch Gesture </th><th align="left">Use </th><th align="left">Discovery </th><th align="left">Feedback  </th></tr>
<tr>
<td align="left">Touch Enter </td><td align="left">Home buttons </td><td align="left">Periodic gleam in </td><td align="left">Ripple in </td></tr>
<tr>
<td align="left">Touch Hold </td><td align="left">Sustained actions </td><td align="left">Sustained gleams </td><td align="left">Sustained ripples in </td></tr>
<tr>
<td align="left">Touch Dwell </td><td align="left">A hold that reaches 2 seconds </td><td align="left">Clockwise filling circle </td><td align="left">Sustained ripples in </td></tr>
<tr>
<td align="left">Touch Exit </td><td align="left">Button push </td><td align="left">Gleam in and out </td><td align="left">Ripple in and then out </td></tr>
<tr>
<td align="left">Pinch </td><td align="left">Selection and manipulation </td><td align="left">Nearest object glows to 50%, 2 fingers glow </td><td align="left">Line traces path from pinched point </td></tr>
<tr>
<td align="left">Grab </td><td align="left">Moving things to desk canvases </td><td align="left">Nearest object glows to 50%, circle contracts </td><td align="left">Glows to 100%, release dims to 50% </td></tr>
<tr>
<td align="left">Touch Swipe </td><td align="left">Scrolling and sliding </td><td align="left">Directional waves </td><td align="left">Wave ripple </td></tr>
</table>
<h3><a class="anchor" id="AimedGestures"></a>
Aimed gestures</h3>
<p>Aimed communication gestures let you interact with distant objects without directly touching them. Aimed gestures may act on the object your gaze focuses for long enough to dwell and select it. These gestures project visual extensions of your hands that reach out towards far objects, making them feel like touch gestures, using phantom tools to reach out and touch things.</p>
<table class="doxtable">
<tr>
<th align="left">Aimed Gesture </th><th align="left">Use </th><th align="left">Discovery </th><th align="left">Feedback  </th></tr>
<tr>
<td align="left">Long Swipe </td><td align="left">Mode switching </td><td align="left">Wave on view edge </td><td align="left">Full view wave </td></tr>
<tr>
<td align="left">FUTURE: Push </td><td align="left">Moving things to wall canvases </td><td align="left">Dwell on focused wall highlights with push wave on object </td><td align="left">Object floats to wall with air ripples </td></tr>
<tr>
<td align="left">FUTURE: Pull </td><td align="left">Moving things from far canvases </td><td align="left">Dwell on focused wall object highlights pulling waves </td><td align="left">Object floats to hand with air ripples </td></tr>
<tr>
<td align="left">FUTURE: Tap </td><td align="left">Touch controls from afar </td><td align="left">Pointer finger above palm causes circle and beam to target</td><td align="left">Beam shoots to object, ripples outward </td></tr>
</table>
<h2><a class="anchor" id="Interactions"></a>
Interactions</h2>
<p>Objects can have different interactions enabled for control via gestures.</p>
<table class="doxtable">
<tr>
<th align="left">Manipulations </th><th align="left">Use </th><th align="left">Discovery Cues </th><th align="left">Feedback Cues  </th></tr>
<tr>
<td align="left">Click </td><td align="left">Touchable buttons </td><td align="left">Hover lights up </td><td align="left">Ripple outward, pushed, snaps back </td></tr>
<tr>
<td align="left">Move </td><td align="left">Position something precisely </td><td align="left">Arrows on movable axis </td><td align="left">Line from starting point </td></tr>
<tr>
<td align="left">Drag to target</td><td align="left">Place onto a valid target </td><td align="left">Nearby targets light up when the object does </td><td align="left">Nearest valid target lights up </td></tr>
<tr>
<td align="left">Rotate </td><td align="left">Orient something precisely </td><td align="left">Rotation circles around spinnable axis </td><td align="left">Circles indicate rotation degrees </td></tr>
<tr>
<td align="left">Spin </td><td align="left">See all sides of something </td><td align="left">Object spins slightly when hands pass it as from wind </td><td align="left">Object spins to inertial stop </td></tr>
<tr>
<td align="left">Resize </td><td align="left">Resize something precisely </td><td align="left">Stretch arrows at bounds corners </td><td align="left">Arrows indicate scale % </td></tr>
</table>
<h3><a class="anchor" id="InteractionCues"></a>
Interaction Cues</h3>
<p>Meta provides a range of interaction cues that help users discover what they can do and get feedback on how to do it.</p>
<h3><a class="anchor" id="Discovery"></a>
Discovery Cues</h3>
<p>Hover cues let you know what you can do when your hands are near interactive objects.</p>
<h3><a class="anchor" id="Dwell"></a>
Dwell Cues</h3>
<p>Dwell cues let you know that sustaining an action for long enough will result in an action being performed. A circular line drawing in clockwise lets you know how long it will take to complete the circle and perform an action.</p>
<h3><a class="anchor" id="Feedback"></a>
Feedback Cues</h3>
<p>Feedback cues let you know what happens when you do something and if you are about to stop doing it.</p>
<p>You can enable or disable feedback from interactions on a MetaBody using MetaBody.Feedback.</p>
<h3><a class="anchor" id="VisualCues"></a>
Visual Cues</h3>
<p>Visual interaction cues show what the user could do or is doing. Visual cues need to make sense even if the user's sound is turned off.</p>
<table class="doxtable">
<tr>
<th>Visual Cue </th><th>Description  </th></tr>
<tr>
<td>Touchable gleam </td><td>Touchables things periodically gleam </td></tr>
<tr>
<td>Touch wave </td><td>Touching something triggers a small ripple </td></tr>
<tr>
<td>Hover glow </td><td>Touchable objects you point at glow </td></tr>
</table>
<h3><a class="anchor" id="AudioCues"></a>
Audio Cues</h3>
<p>Auditory interaction cues support the visuals by giving a clear sense of when something is happening even when the user may be confused by overcrowded visuals or backgrounds.</p>
<table class="doxtable">
<tr>
<th>Audio Cue </th><th>Description  </th></tr>
<tr>
<td>Hover </td><td>Hovering over objects that can be touched triggers a faint sound </td></tr>
<tr>
<td>Touch </td><td>Touching an object collider triggers an impact in proportion to the velocity of the touch </td></tr>
<tr>
<td>Selection </td><td>Touching an object that becomes selected </td></tr>
<tr>
<td>Deselection </td><td>When an object becomes deselected </td></tr>
<tr>
<td>Rub </td><td>Sliding a finger along an object's surface triggers a rubbing sound </td></tr>
<tr>
<td>Click </td><td>Touching objects triggers an impact in proportion to the velocity of the touch </td></tr>
<tr>
<td>Collision </td><td>When objects bump into each other </td></tr>
<tr>
<td>Key press </td><td>Touching keyboard keys </td></tr>
<tr>
<td>Grab </td><td>When your hand closes on an object </td></tr>
<tr>
<td>Release </td><td>When your hand opens and releases an object </td></tr>
<tr>
<td>Scale </td><td>When you are scaling something up </td></tr>
<tr>
<td>Stretch </td><td>When you are changing something's proportions </td></tr>
<tr>
<td>Alert </td><td>An alert sound for a notification that demands attention </td></tr>
<tr>
<td>Notification </td><td>A notification that can be ignored </td></tr>
</table>
<h1><a class="anchor" id="CollisionMaterials"></a>
Collision Materials</h1>
<p>The sounds objects make when they collide should depend on the material of the objects. Here are some example material sound effects that would be appropriate for different scenarios:</p>
<table class="doxtable">
<tr>
<th>Physics Material </th><th>Examples  </th></tr>
<tr>
<td>Energy </td><td>Panels </td></tr>
<tr>
<td>Plastic </td><td>Default material </td></tr>
<tr>
<td>Metal </td><td>Wastebasket </td></tr>
<tr>
<td>Wood </td><td>Floor </td></tr>
<tr>
<td>Dirt </td><td>The ground </td></tr>
<tr>
<td>Water </td><td>Rain effects </td></tr>
<tr>
<td>Bubble </td><td>Poppable bubbles </td></tr>
<tr>
<td>Paper </td><td>Sticky notes </td></tr>
</table>
<h1><a class="anchor" id="InteractionSpaces"></a>
Interaction Spaces</h1>
<p>There are several spaces where Meta objects can be attached for interaction. Initially, most objects start out in orbital space until they are placed on a canvas.</p>
<table class="doxtable">
<tr>
<th align="left">Interaction Space </th><th align="left">Description </th><th align="left">Examples  </th></tr>
<tr>
<td align="left">HUD </td><td align="left">Camera-attached sticky HUD </td><td align="left">Time, status alerts </td></tr>
<tr>
<td align="left">Orbital Focus </td><td align="left">Object in front of you that you are focused on </td><td align="left">Seeing the week forecast in a single view - objects respond to the user’s focus </td></tr>
<tr>
<td align="left">Orbital Eye-Level </td><td align="left">Objects orbiting around the user </td><td align="left">Multi-tasking panels you can switch between </td></tr>
<tr>
<td align="left">Orbital Sky-Level </td><td align="left">Objects above the user </td><td align="left">Search, time, calendar, weather, time zones for global contacts </td></tr>
<tr>
<td align="left">Hand </td><td align="left">Objects tracked to the user’s hand </td><td align="left">Looking at a wrist with watch time and fingertip menu </td></tr>
<tr>
<td align="left">Surround </td><td align="left">“Full-screen” Apps that surround us </td><td align="left">Weather watching, stargazing, tracking the arc of the sun to see time zones friends are in, expanded molecular structures </td></tr>
<tr>
<td align="left">Holodeck </td><td align="left">Virtual surround environments, like physical spaces with virtual canvases </td><td align="left">Viewing other canvassed environments we've placed objects in, architectural walk-through </td></tr>
<tr>
<td align="left">Canvas </td><td align="left">Objects attached to physically tracked canvases </td><td align="left">Sculpting models on tables </td></tr>
<tr>
<td align="left">World </td><td align="left">Objects technically anchored to nearby canvases and SLAM but offset enough to appear to float untethered between them </td><td align="left">Store fronts, museum exhibits, design prototypes, solar system chandeliers </td></tr>
</table>
<h3>HUD Space</h3>
<p>HUD-attached objects appear to be stuck to the camera.</p>
<p>Alerts and notifications appear in HUD space to ensure visibility. Status indicators may also be HUD-attached.</p>
<h3>Orbital Space</h3>
<p>Orbital space is a conceptual GUI bubble around you that follows you and orients towards your forward facing direction until you turn far enough for it to re-target into a new direction.</p>
<p>The area that users can reach around them with their hands can be visualized as a sphere with the default reach distance radius of 0.4m.</p>
<p>Current canvases are in the forward-facing direction and to the left and right.</p>
<p>Menu canvases are below eye-level, angled upwards.</p>
<p>Meta widgets need to be reachable by people’s hands in order to be interacted with.</p>
<ul>
<li>Interfaces tuned for people with long arms will be difficult to reach for smaller people.</li>
<li>Default reach distance is 0.4m which should support short arm reach distances so that everyone can use it.</li>
<li>Orbital space can scale down for small person reach.</li>
<li>Widgets should be placed as low as possible for ease of interaction without needing to reach too high.</li>
<li>People should be able to interact by moving things into their current focus direction without always having to turn their head between things.</li>
</ul>
<h3>Front Orbital Focus</h3>
<p>Front Orbital Focus is a self-contained interaction space that fits in-screen without the need to look around.</p>
<p>Each individual has varying eye and arm distances. These distances are used to adjust the distance of user interface elements around you, and the calibration of the cameras for stereoscopic focus.</p>
<h3>Orbital Surround Space</h3>
<p>Sometimes we want to anchor things to our entire space so we can explore by looking all around us. Stargazing is a good example of this kind of space. It may be geospatially aligned with the night sky where you are, but it surrounds your orbital space without being anchored to any physical objects.</p>
<h2>Hand Space</h2>
<p>Hand space is the surroundings in which the hand gestures are recognized - that is, the space in which direct gestures can be used to manipulate objects within reach distance.</p>
<h3>Hand Gestures</h3>
<p>The gestures that are currently supported include:</p><ul>
<li>Grabbing</li>
<li>Pinching</li>
<li>Touching</li>
</ul>
<p>For a full list of supported gestures, refer to the <a class="el" href="_m_a_p_g.html#MetaBehaviour">MetaBehaviour Scripting Guide</a>.</p>
<h3>Boundaries</h3>
<p>Frame rate is affected by interactions done in hand space. Expect frame rate reductions if</p><ul>
<li>2 hands are simultaneously in Camera view</li>
<li>Fingertip detection</li>
<li>The point cloud display is turned on</li>
</ul>
<h2>Canvas Spaces</h2>
<p>A canvas is a part of a tracked physical surface suitable for placing objects.</p>
<p>When you map objects in your close environment and interact with them, you can translate (move around) relative to them, making them smaller by moving away or oblique by turning around them.</p>
<h3>Recognize the canvases around you</h3>
<p>You can recognize canvases on flat surfaces like desks, walls and boxes within a 2 meter sensor range.</p>
<h3>Targeting Canvases</h3>
<p>You look at a place where the crosshair appears and locks on after 2 seconds.</p>
<h2>Holodeck Spaces</h2>
<p>A holodeck space is a virtual scene expanded to life-size around you, allowing you to interact with it as though it were a physical environment that you were in.</p>
<ul>
<li>Holodeck spaces can add virtual objects to the world around you.</li>
<li>Virtual canvases on virtual scenery can be used much like physical surface canvases.</li>
<li>Holodecks can be made opaque for use as virtual reality.</li>
</ul>
<h3>Virtual Canvases</h3>
<p>Virtual canvases let you simulate a holodeck room having canvases on it that you can interact with.</p>
<h3>World Space</h3>
<p>World space objects are technically anchored to nearby canvases and SLAM but offset enough to appear to float un-tethered between them and not to vanish until all targets in its world set aren't visible.</p>
<h3>Interactions between spaces</h3>
<p>How do you make multiple spaces useable without the user having to “switch modes” with an unnecessary extra interaction? In the case of the sky and the wrist, it is governed by where you look (upwards towards the sky or down towards your wrist). Both just work and can work even at the same time (eg. holding your wrist up against the sky).</p>
<h1><a class="anchor" id="MetaOS"></a>
The Meta OS</h1>
<p>In the future, you will be able to use Meta to multi-task between Apps - this will be the Meta operating system. The following subsections explain some of the features that are planned to be included:</p>
<h2><a class="anchor" id="MultiTasking"></a>
Multi-tasking</h2>
<p>Though the world is an infinite canvas and everything can be spatially navigated just by moving around, people sometimes want to be able to accomplish many things without moving and need a way to switch contexts and Apps from where they currently are.</p>
<h3><a class="anchor" id="BeltMenu"></a>
The belt menu</h3>
<p>The belt menu lets you launch and manage your favorite Apps.</p>
<ul>
<li>If you launch an App that isn't normally on your belt, it is added to your belt while it is open.</li>
</ul>
<h3><a class="anchor" id="AppsMenu"></a>
The Apps menu</h3>
<p>The apps menu lists all your Apps.</p>
<h3><a class="anchor" id="AppIcons"></a>
App icons</h3>
<p>Each Meta App has an icon that appears in the Apps menu.</p>
<h3><a class="anchor" id="AppStore"></a>
The %Meta App Store</h3>
<p>The Meta App Store is an upcoming feature that will allow you to download Apps created by other developers and upload your own Apps to the Store for distribution.</p>
<h2>Navigation</h2>
<p>Meta UIs allow new kinds of navigation that require special consideration in order to prevent users from getting lost in a world where they can look in every direction.</p>
<h3>OS-Level Navigation</h3>
<table class="doxtable">
<tr>
<th>Navigation action </th><th>Interaction  </th></tr>
<tr>
<td>Launch App </td><td>Touch the App icon on the belt or home </td></tr>
<tr>
<td>Close App </td><td>Smack the belt App icon down towards the ground </td></tr>
<tr>
<td>Minimize App </td><td>Touch a running App's icon to hide it </td></tr>
</table>
<h3>In-App Navigation</h3>
<p>Within your App, you have several navigation options:</p>
<table class="doxtable">
<tr>
<th>Navigation style </th><th>Purpose </th><th>Example  </th></tr>
<tr>
<td>A single object you touch to use </td><td>Panel-less UI mimics real devices </td><td>A hand-held music player widget </td></tr>
<tr>
<td>Panels with nav between </td><td>Hierarchical info Apps </td><td>Meta SDK Guide </td></tr>
<tr>
<td>Web UI </td><td>Using existing interfaces </td><td>Facebook </td></tr>
<tr>
<td>Many more... </td><td>Augmented reality is a new horizon</td><td>Be creative and inspired by sci-fi </td></tr>
</table>
<h1><a class="anchor" id="Settings"></a>
Settings Panels</h1>
<h3>App Settings Panels</h3>
<p>Some Apps need to have settings and it is easiest to make an MGUIPanel with Settings controls in it.</p>
<p>How should you get to your settings panel?</p>
<p>It is a good idea to put a settings button with the <a class="el" href="_m_h_i_g.html#SettingsIcon">settings icon</a> above your App that toggles the Settings panel on and off.</p>
<h3>Intrinsic Settings Toggles</h3>
<p>Many things in Apps can be toggled or customized via settings. A dedicated settings panel is not always necessary however.</p>
<p>Many pieces of information can toggle their display settings just by touching them. More complex toggling interactions may be done by, for example, looking at an object and making a gesture, throwing it out or flipping a switch.</p>
<h2><a class="anchor" id="SettingsIcon"></a>
The Settings Icon</h2>
<p>Meta has a standard Settings icon for use as a button to toggle settings panels on and off.</p>
<p>You can also register your App's settings with the central settings list, which can link you to any App's settings panel and then allow you to return back to your App.</p>
<h2><a class="anchor" id="MetaSettings"></a>
The Meta Settings Panel</h2>
<p>Meta Main settings panel lets you configure your Meta system.</p>
<h1><a class="anchor" id="Principles"></a>
Principles of Meta Usability</h1>
<h2>Augmented reality considerations</h2>
<p>Stereoscopic 3D display requires different visual considerations compared to 3D graphics rendered on a flat 2D display.</p>
<ul>
<li><b>Avoid Billboarding:</b> Billboarding sprites look really fake in stereo. 3D trees relying on combining a myriad of sprites might look convincing on 2D displays, but in stereo it looks like a bunch of flat cutouts with clearly distinguishable flatness.</li>
<li><b>Avoid Visual Crowding:</b> Placing many visual elements close together or in front of each other can confuse the eyes and provide conflicting depth cues.</li>
</ul>
<h1><a class="anchor" id="Jaysification"></a>
Jaysification</h1>
<p>The visual style of UI in the Metaverse is based on Jayse Hansen's holographic user interface designs for films including Iron Man, The Avengers, Ender's Game, The Hunger Games and Robocop. You can learn more about Jayse's work from his site, <a href="http://jayse.tv/v2/?portfolio=hud">Jayse.tv</a>.</p>
<h3>Jaysification Principles</h3>
<p>There are a range of different styles in these films, but a few principles derived from these apply to Meta interfaces and constitute the "Jaysification" visual style.</p>
<ul>
<li>Wireframe line segments are thin, with hidden line removal to avoid visual crowding and ugly diagonals bisecting every quad face.</li>
<li>Key points have dots that stand out between the line segments, giving the eye clear points with disparity the eye understands as depth. This works better than with a large surface filled with color.</li>
<li>Surface materials are fresnel shaded by default, making their edges lit up while the centers of objects pointed towards the observer looks see-through. This creates an appearance similar to X-rays and electron microscopy images.</li>
</ul>
<p>When designing for Meta, you can easily implement the Jaysification look by attaching the MetaBody component to any game object and enabling Jaysify.</p>
<p>This automatically converts the object to have a Jaysified wireframe and a fresnel shaded surface material.</p>
<p>You can combine Jaysification effects with custom surface materials as well by enabling "Preserve surface materials".</p>
<h1><a class="anchor" id="MetaBody"></a>
MetaBody</h1>
<p>MetaBody objects in Meta can take on a range of interactivity properties.</p>
<table class="doxtable">
<tr>
<th>MetaBody Property </th><th>Effect  </th></tr>
<tr>
<td>Grabbable </td><td>Responds to a grab gesture. </td></tr>
<tr>
<td>Arrow </td><td>You learn how to follow objects around you in orbital space. If it goes out of view, an arrow points towards it till you catch up to it. </td></tr>
</table>
<p>For a full listing of the capabilities of MetaBody, refer to the MetaBody reference.</p>
<h1><a class="anchor" id="Animation"></a>
Animation</h1>
<p>Animations are a great way of moving content in Meta space. With our stereoscopic lenses you are able to create beautiful animations in the 3D space. Animations can convey feedback to the user. Some care must be taken while implementing animations.</p>
<ul>
<li>Use animation to increase your user’s understanding of your App. For example, use an animation to show the change of states of an item in your App.</li>
<li>Overuse of animation can confuse the user.</li>
<li>Avoid excessive use of the Z axis - this can cause motion sickness and eye strain for your users.</li>
<li>Avoid bringing objects very close to the camera. This is considered gimmicky and takes the user away from your experience.</li>
<li>Ease animations in and out. This means that animations will start and finish smoothly rather than jerking.</li>
<li>Quick fade in and fade outs are the easiest thing for your user’s eye to see. Don’t get too complicated with transition animations.</li>
<li>Fade ins can move slightly closer to the camera in the Z axis, and fade outs may move slightly away from the camera.</li>
<li>Make animations as realistic and natural as possible. Meta design principles strive to merge the physical and digital world.</li>
<li>Observe interactions in the real world and try and emulate their speed and motion. Give animations a physical weight and feel.</li>
<li>Use animations to show where objects are moving over time, rather than snapping directly to the end destination. This will keep your user spatially aware.</li>
<li>Make animations quick and fluid. You don’t want your user to be waiting around for your animation to finish.</li>
<li>Use consistency with your animations within your App and the MetaSpace environment.</li>
</ul>
<h1><a class="anchor" id="Colors"></a>
Additive Colors</h1>
<p>Optical see-through augmented reality with additive projected graphics poses unique color considerations.</p>
<h2><a class="anchor" id="AdditiveGraphics"></a>
Additive Graphics: Black is the new whitespace</h2>
<p>With additive projected see-through graphics, you can only brighten and tint reality. Black shows up as nothing and is see-through.</p>
<p>Bright white background conditions can make it hard to see such graphics.</p>
<p>Translucency helps to create graphics that you can see in space without overpowering the world around you.</p>
<div class="image">
<img src="MetaHologram.jpg" alt="MetaHologram.jpg"/>
<div class="caption">
Holograms have additive colors that brighten reality, making them clearer against dark backgrounds.</div></div>
 <h2>Color Palette</h2>
<p>Bright colors and white are your best friends with additive AR.</p>
<p>MGUI has an overall blue theme that rarely uses completely solid colors. There are different opacities of blue for UI elements, with accents of green for selections, red for cancellations, and object material colors of yellow, orange and purple for breaking up parts of Jaysified hologram models.</p>
<div class="image">
<img src="MetaColorPalette.png" alt="MetaColorPalette.png"/>
<div class="caption">
Some of the additive color swatches in the MGUI Sprite Atlas </div></div>
 <h1><a class="anchor" id="Typography"></a>
3D Typography</h1>
<p>Meta’s default font is called Meta Sans. It is currently based on Helvetica Neue, but it may change in future. By using Meta Sans, you are ensured your type will stay updated in future releases.</p>
<p>When designing text in stereoscopic 3D, some special considerations apply:</p>
<ul>
<li><b>3D text with things behind it may confuse the eye.</b> Avoid this by providing a semi-opaque background panel or outline around the text.</li>
<li><b>Use solid type.</b> Font outlines should be avoided as they detract from the cleanness of typography. Wherever possible, use a fill behind the text to protect it from background clutter rather than outlining it.</li>
<li><b>Font size is a not a guarantee of readability.</b> The actual effective readability of type depends on distance, angle, font weight, color contrast, 3D panel backing to help focus the eyes, motion of orbital, anchored or HUD-fixed elements and a myriad of other factors.</li>
<li>**Meta SDK Guide shows examples of readable type.** The minimum readable size is currently shown in the SDK Guide App’s labels example. Compare any text to these examples which show various forms of type and the sizes and supporting attributes necessary to make them readable such as background colors, etc.</li>
</ul>
<h1><a class="anchor" id="Icons"></a>
Icons and Graphics</h1>
<h2>App Icons</h2>
<p>Meta Apps have icons which can be assigned in their MetaAppObject.</p>
<h1><a class="anchor" id="Wording"></a>
Wording &amp; Terminology</h1>
<p>The world of augmented reality (AR) has a lot of new concepts and abbreviations for people to get used to, so AR Apps ought to reassure users by using the clearest language possible to explain things.</p>
<h3>Instructing users on how to perform gestures</h3>
<p>When talking about hitting buttons, use the word "touch" similar to how it is used for tablets and phone touch interfaces. For example, "Touch here" instead of "Click here".</p>
<h3>Show, don't tell</h3>
<p>When you need to tell a user how to do something, you don't always need to resort to words.</p>
<p>Sometimes the placement of a elements will help suggest what something is meant to do.</p>
<p>For example, a glowing round platform with an object hovering over it may suggest that the object is grabbable and an object spins very slowly may suggest that it is spinnable.</p>
<h1><a class="anchor" id="UIElements"></a>
UI Elements</h1>
<h2>Panel &amp; Hologram Elements</h2>
<p>Meta has 2 main kinds of interfaces: panels and holograms.</p>
<ul>
<li><b>Panels:</b> 2D GUIs projected onto planes in 3D with gestures emulating a mouse.</li>
<li><b>Holograms:</b> 3D objects you touch with your hands to manipulate.</li>
</ul>
<h2>Panel Elements</h2>
<p>You can use the MGUI system to create beautiful 3D GUIs for Meta. MGUI is based on Unity’s next-generation GUI system (created by the author of <a href="http://www.tasharen.com/?page_id=140">NGUI</a>), and it provides a number of standard components to craft your own UIs, including panels, buttons and sliders.</p>
<p>You can also add holographic 3D objects onto your panels.</p>
<h2><a class="anchor" id="HologramElements"></a>
Hologram Elements</h2>
<p>These elements help build 3D objects that you can manipulate gesturally.</p>
<ul>
<li><b>MetaBody component:</b> A component you add to any 3D Unity GameObject that lets you quickly toggle options like supported gestures, interactions, tracking, audiovisual feedback and more.</li>
<li><b>MetaBehaviour-derived scripts:</b> A type of C# script you write and attach to an object to make it react to gesture-based events.</li>
</ul>
<h2><a class="anchor" id="MetaPrimitives"></a>
MetaPrimitives</h2>
<div class="image">
<img src="MetaPrimitives.jpg" alt="MetaPrimitives.jpg"/>
<div class="caption">
MetaPrimitives are instantly usable holograms</div></div>
<p> A set of hand-sized primitive shapes optimized for use with Meta.</p>
<table class="doxtable">
<tr>
<th>MetaBody default property </th><th>Purpose  </th></tr>
<tr>
<td>Scale 0.05 (5cm across) </td><td>Fits in 23 degree FOV and your hand </td></tr>
<tr>
<td>MetaBody pre-attached </td><td>Meta capabilities one click away </td></tr>
<tr>
<td>MetaBody.grabbable </td><td>Grab and release enabled </td></tr>
<tr>
<td>MetaBody.moveable </td><td>Grab and release to move it </td></tr>
<tr>
<td>MetaBody.feedback </td><td>Object glows when grabbing </td></tr>
<tr>
<td>MetaBody.jaysify </td><td>Makes objects look holographic </td></tr>
</table>
<table class="doxtable">
<tr>
<th>MetaPrimitive </th><th>Example Uses  </th></tr>
<tr>
<td>MetaCube </td><td>Game grid blocks </td></tr>
<tr>
<td>MetaRoundedCube </td><td>App icon buttons </td></tr>
<tr>
<td>MetaSphere </td><td>Rollable balls </td></tr>
<tr>
<td>MetaCylinder </td><td>Rotating objects </td></tr>
<tr>
<td>MetaCapsule </td><td>Moveable character container </td></tr>
<tr>
<td>MetaQuad </td><td>Disable MetaBody.jaysify and place additive sprite textures </td></tr>
</table>
<h2>Panel MGUI</h2>
<p>MGUI is the set of Meta-optimized GUI elements you can build with.</p>
<p>These elements are in Meta SDK and ready to use.</p>
<h2><a class="anchor" id="MGUIContainers"></a>
MGUI Containers</h2>
<p>You must place GUI containers before placing other controls inside of them.</p>
<table class="doxtable">
<tr>
<th>MGUI Container Prefabs </th><th>Purpose  </th></tr>
<tr>
<td>MGUIRoot </td><td>The invisible root prefab for a set of MGUI user interface elements. Put this underneath your root MetaAppObject before adding MGUIPanels and controls under those. If you don't use MGUIRoot first, controls you place will not be scaled correctly. </td></tr>
<tr>
<td>MGUIPanel </td><td>A 3D window for grouping MGUI widgets together. Give it a title, fill it with controls and size its sprite background to fit its contents. </td></tr>
</table>
<h2><a class="anchor" id="MGUIControls"></a>
MGUI Controls</h2>
<p>MGUI Controls are the actual widgets you can touch to do things. You place these inside of MGUI Containers like MGUIPanels.</p>
<table class="doxtable">
<tr>
<th>MGUI Controls </th><th>Purpose  </th></tr>
<tr>
<td>MGUIButton </td><td>A pressable button. </td></tr>
<tr>
<td>MGUICheckbox </td><td>A toggleable boolean switch. </td></tr>
<tr>
<td>MGUIRadioButtons </td><td>A set of toggleable choices. </td></tr>
<tr>
<td>MGUISlider </td><td>An adjustable value slider. </td></tr>
<tr>
<td>MGUIInput </td><td>An input text area. When you touch it, the MetaKeyboard appears. </td></tr>
<tr>
<td>MGUIScrollbar Horizontal </td><td>A scrollbar for horizontal scrolling. </td></tr>
<tr>
<td>MGUISCrollbar Vertical </td><td>A scrollbar for vertical scrolling. </td></tr>
<tr>
<td>MGUIScrollableArea </td><td>A scrollable area of GUI that masks the parts outside the visible area. </td></tr>
</table>
<h3>Future MGUI Controls</h3>
<p>These elements are coming in future SDK releases.</p>
<ul>
<li>Meta Colors: A color picker.</li>
<li>MetaTextArea: A multi-line text area that uses MetaKeyboard for input.</li>
<li>MetaTextLink: Text that can be clicked to open a single designated link in MetaWeb.</li>
<li>MetaTextArea: An editable multi-line text box.</li>
<li>MetaWeb: A 3D web browser. The full MetaBrowser App can be used for browsing.</li>
<li>MetaWeb Widget: can be used minimally for HTML5-based GUI elements.</li>
</ul>
<h1><a class="anchor" id="Layers"></a>
Layers</h1>
<div class="image">
<img src="MetaCameraLayers.jpg" alt="MetaCameraLayers.jpg"/>
<div class="caption">
Camera layers let you set the order in which things are rendered.</div></div>
<p> There are several layers of content:</p>
<table class="doxtable">
<tr>
<th>Layer </th><th># </th><th>Purpose </th><th>Example  </th></tr>
<tr>
<td>Default </td><td>0 </td><td>The objects in the world. </td><td>Holograms and panels </td></tr>
<tr>
<td>Ignore Raycast </td><td>2 </td><td>Non-interactive elements </td><td>Alert messages on objects </td></tr>
<tr>
<td>UI </td><td>5 </td><td>Widgets </td><td>Object highlights </td></tr>
<tr>
<td>HUD </td><td>9 </td><td>This renders above everything else no matter what. </td><td>Notifications, Dialogs, Indicators, Interaction Gizmos </td></tr>
<tr>
<td>Dimmed </td><td>14 </td><td>Diminish visual crowding and disabling UI controls. </td><td>Recent Apps, UI behind modal dialogs </td></tr>
<tr>
<td>Background </td><td>15 </td><td>Behind everything else. </td><td>RGB Sensor feed go to help onlookers understand how the graphics are overlaid on reality. </td></tr>
<tr>
<td>Invisible </td><td>16 </td><td>Hidden elements visible in editor but not to camera </td><td>Gizmos, while still being visible and editable in the scene view. </td></tr>
</table>
<p>Some objects may be obscured partially by objects, but this can be useful as they may provide discovery feedback that is visible through obstructions and be interactive to touch.</p>
<p>For more information on how these layers can be programmed, see <a class="el" href="_m_a_p_g.html#MAPGLayers">Layers &amp; Camera Depths</a>.</p>
<h1><a class="anchor" id="Modal"></a>
Modal States</h1>
<p>There are several kinds of states that need to be modal and prevent other input until they are completed.</p>
<h2>Dialog Panels</h2>
<p>Dialog panels let Apps send and receive information to users. See <a class="el" href="_m_a_p_g.html">Meta App Programming Guide</a> for details on how to trigger dialogs.</p>
<ul>
<li>Dialogs can appear in front of panels.</li>
<li>Panels that need to be in front of others like dialogs can dim the panels behind them.</li>
<li>Dialogs usually have a cancel button at a minimum.</li>
</ul>
<h3>Alerts</h3>
<p>Alerts bring urgent Status messages and require confirmation from the user before being dismissed. These appear on the HUD layer so you can’t miss them.</p>
<h3>Prompts</h3>
<p>Prompts are dialogs that ask for the user to enter data such as text. These have validations to ensure the provided data meets the prompt's criteria before it can accept it.</p>
<h2>Notifications</h2>
<p>People can receive notifications in the periphery of their view without interrupting their activities modally as with dialogs.</p>
<ul>
<li>Notifications can be touched while they are visible to trigger a response action.</li>
<li>If their timer expires, they go in the Notifications list for later review.</li>
<li>Notifications queue in a list so you can see several in a row.</li>
</ul>
<h1><a class="anchor" id="GraphicsImport"></a>
Graphics Import Guide</h1>
<p>If you have skills in making 2D UI graphics and/or motion graphics, you can easily import your art assets into Meta to help mock up UIs as you make them fully interactive.</p>
<h2>Image Assets</h2>
<ol type="1">
<li>Export graphics in any format Unity understands.</li>
<li>Place it inside your Meta project folder.</li>
<li>In the Unity Editor, click on the asset in Project panel.</li>
<li>Set Type to Sprite.</li>
<li>Drag the sprite asset into the scene Hierarchy list.</li>
<li>Scale and position it within the panel you want it to be part of.</li>
<li>Keep it as a guide to sizing MGUI controls to match and leave it around to toggle its active on and off when you want to consult the original mockups.</li>
</ol>
<h2>Motion Graphics Assets</h2>
<ol type="1">
<li>Export regions of your motion graphics as video clips in MP4 or OGV (Theora) format.</li>
<li>Import them as MovieTextures and use MetaMovieTexture script to make them play in Unity. </li>
</ol>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Thu Dec 18 2014 17:35:35 by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.8 </li>
  </ul>
</div>
</body>
</html>
